# Hateful-Meme-Detection

<img width="307" height="411" alt="download (1)" src="https://github.com/user-attachments/assets/118fa844-0644-47df-a4a4-6a04b5edae96" />

This project implements a multimodal hateful meme detection system using CLIP (ViT-B/32) to understand both images and text.
A lightweight neural classifier is trained on top of CLIP embeddings to classify memes as:
 Hateful or Not Hateful
 

# Goal: Build a practical baseline for automated hateful content moderation.

# Dataset

Facebook Hateful Memes Dataset

ğŸŸ¢ Train: train.jsonl

ğŸ”µ Validation: dev.jsonl

âš« Test: test.jsonl (no labels, inference only)

âš¡ For fast experimentation, a filtered subset (~900 samples) was used.
All JSON files were filtered to match existing images to avoid broken samples.

# Model Architecture

Backbone:

ğŸ”¥ CLIP ViT-B/32 (Frozen Feature Extractor)

#Pipeline:

ğŸ–¼ï¸ Image â†’ clip.encode_image

ğŸ“ Text â†’ clip.encode_text

ğŸ“ Feature Normalisation

ğŸ”— Concatenation (Image + Text)

# Classifier Head:

Linear(1024 â†’ 256) + ReLU

Linear(256 â†’ 2)

âš™ï¸ Training Setup

ğŸ§ª Loss: Cross-Entropy Loss

ğŸš€ Optimiser: AdamW

ğŸ–¥ï¸ Acceleration: CUDA (GPU)

ğŸ§¯ Stability: Gradient Clipping

ğŸ“Š Metrics: Accuracy, Precision, Recall, F1-score

ğŸ§  CLIP Backbone: Frozen for stability

ğŸ“ˆ Results (Subset)

âœ… Training Accuracy: Improved steadily

ğŸ“Š Validation Accuracy & F1: Improved across epochs

# Interpretation: Model learns meaningful multimodal patterns

âš ï¸ Note: Scores are lower due to small dataset size and frozen CLIP

ğŸ–¼ï¸ Inference Demo (Human Evaluation)

A demo script is included to:

ğŸ² Randomly pick a meme from test.jsonl

ğŸ‘€ Display the image + text

ğŸ¤– Show the modelâ€™s prediction (Hateful / Not Hateful)

ğŸ§ª This allows visual inspection of model behaviour without needing labels.

# Limitations

ğŸ“‰ Trained on a small subset of data

ğŸ§Š CLIP backbone not fine-tuned yet

âš–ï¸ Dataset is class-imbalanced

ğŸ§ª Test set has no labels (dev set used for evaluation)

ğŸš§ Future Work (Work in Progress)

ğŸ“ˆ Train on the full dataset

ğŸ”“ Fine-tune last layers of CLIP

âš–ï¸ Handle class imbalance with weighted loss

ğŸ” Add error analysis + confusion matrix

ğŸ§© Ensemble Moderation System (Planned):

Combine CLIP classifier + Vision-Language LLM (BLIP-2 / LLaVA)

Add rule-based heuristics for sensitive symbols & protected groups

Fuse predictions using a meta-classifier / decision logic

â–¶ï¸ How to Run

1ï¸âƒ£ Download & unzip dataset
2ï¸âƒ£ Update paths for JSON + image folders
3ï¸âƒ£ Train model
4ï¸âƒ£ Run inference demo on test samples

# Acknowledgements

ğŸ”— OpenAI CLIP

ğŸ“š Facebook Hateful Memes Dataset

âš™ï¸ PyTorch, Google Colab, Kaggle
